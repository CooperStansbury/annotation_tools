{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "NOTES:\n",
    "    - this notebook has two parts:\n",
    "        (1) clean the `reference`, or the raw, unannotated documents\n",
    "        (2) map the annotations back onto this reference\n",
    "    - accuracy is more important than speed\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import hashlib\n",
    "import numpy as np\n",
    "import spacy\n",
    "import re\n",
    "import random\n",
    "from importlib import reload\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "from pprint import pprint\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import seaborn as sns\n",
    "\n",
    "#local\n",
    "import utility_funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse Unannotated Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(utility_funcs)\n",
    "\n",
    "def cosemetic_clean(document):\n",
    "    \"\"\"A function to perform minor text processing\n",
    "    in hopes of making sentence parsing more robust\n",
    "    \n",
    "    Args:\n",
    "        - document (str): a document\n",
    "        \n",
    "    Returns:\n",
    "        clean_document (str): a document with minor adjustments    \n",
    "    \"\"\"\n",
    "    decoded_doc = utility_funcs.force_encoding(document)\n",
    "    clean_document = re.sub(' +', ' ', decoded_doc).replace(\"_\", \"\")\n",
    "    return clean_document\n",
    "    \n",
    "    \n",
    "def parse_documents(d_map):\n",
    "    \"\"\"A function to add parsed documents to dmap\n",
    "    \n",
    "    NOTE: modifies `d_map` in place, does not make a copy\n",
    "    \n",
    "    Args:\n",
    "        - d_map (dict): a document map created in the preprocessing\n",
    "            step\n",
    "            \n",
    "    Returns:\n",
    "        - d_map (dict): a document map created in the preprocessing\n",
    "            step\n",
    "    \"\"\"\n",
    "    for ICD_id, content in d_map.items():\n",
    "        pre_parse = cosemetic_clean(content['raw_content'])\n",
    "        parsed = nlp(pre_parse)\n",
    "        sentences = list(parsed.sents)\n",
    "        \n",
    "        content['parsed'] = parsed\n",
    "        content['sentences'] = sentences\n",
    "        \n",
    "    return d_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 1 µs, total: 4 µs\n",
      "Wall time: 6.2 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "d_map_path = \"processed_annotations/DOCUMENT_MAP_02-14-2020.json\"\n",
    "d_map = json.load(open(d_map_path))\n",
    "\n",
    "d_map = parse_documents(d_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['raw_content', 'from_file', 'parsed', 'sentences'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_map['10932687'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ICD_doc_id</th>\n",
       "      <th>sentece</th>\n",
       "      <th>start_pos</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_chars</th>\n",
       "      <th>sentece_obj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>95581557</td>\n",
       "      <td>Ct) MERCY HEALTH \\n</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>(Ct, ), MERCY, HEALTH, \\n)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95581557</td>\n",
       "      <td>GRAND RAPIDS,</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>(GRAND, RAPIDS, ,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>95581557</td>\n",
       "      <td>Ml \\nCONSENT</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>(Ml, \\n, CONSENT)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>95581557</td>\n",
       "      <td>TO RECEIVE \\n</td>\n",
       "      <td>44</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>(TO, RECEIVE, \\n)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>95581557</td>\n",
       "      <td>Patient Label \\n\\nNON-EMERGENCY TRANSFUSION OF...</td>\n",
       "      <td>56</td>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "      <td>(Patient, Label, \\n\\n, NON, -, EMERGENCY, TRAN...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ICD_doc_id                                            sentece  start_pos  \\\n",
       "0   95581557                                Ct) MERCY HEALTH \\n          0   \n",
       "1   95581557                                      GRAND RAPIDS,         18   \n",
       "2   95581557                                       Ml \\nCONSENT         32   \n",
       "3   95581557                                      TO RECEIVE \\n         44   \n",
       "4   95581557  Patient Label \\n\\nNON-EMERGENCY TRANSFUSION OF...         56   \n",
       "\n",
       "   num_words  num_chars                                        sentece_obj  \n",
       "0          5         18                         (Ct, ), MERCY, HEALTH, \\n)  \n",
       "1          3         13                                 (GRAND, RAPIDS, ,)  \n",
       "2          3         11                                  (Ml, \\n, CONSENT)  \n",
       "3          3         12                                  (TO, RECEIVE, \\n)  \n",
       "4          9         50  (Patient, Label, \\n\\n, NON, -, EMERGENCY, TRAN...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "I'll build a reference data frame with all sentences\n",
    "\"\"\"\n",
    "new_rows = []\n",
    "\n",
    "for ICD_id, content in d_map.items():\n",
    "    for sent in content['sentences']:\n",
    "        \n",
    "        row = {\n",
    "            'ICD_doc_id':str(ICD_id),\n",
    "            'sentece': sent.text,\n",
    "            'start_pos':sent.start_char,\n",
    "            'num_words':len(sent),\n",
    "            'num_chars':len(sent.text),\n",
    "            'sentece_obj': sent,\n",
    "        }\n",
    "        new_rows.append(row)\n",
    "        \n",
    "ref = pd.DataFrame(new_rows)\n",
    "ref.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                  Ct) MERCY HEALTH \\n\n",
       "1                                        GRAND RAPIDS,\n",
       "2                                         Ml \\nCONSENT\n",
       "3                                        TO RECEIVE \\n\n",
       "4    Patient Label \\n\\nNON-EMERGENCY TRANSFUSION OF...\n",
       "Name: sentece, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref['sentece'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "save the reference\n",
    "\"\"\"\n",
    "ref.to_csv(\"processed_annotations/reference.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load (and save) Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ICD_doc_id</th>\n",
       "      <th>json_filename</th>\n",
       "      <th>annotator</th>\n",
       "      <th>annotation_id</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>start_char</th>\n",
       "      <th>end_char</th>\n",
       "      <th>text</th>\n",
       "      <th>sentence_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>95581557</td>\n",
       "      <td>../data/2020-01-21_Random_46-60_KATHLEEN.json</td>\n",
       "      <td>KATHLEEN</td>\n",
       "      <td>22668539</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2613</td>\n",
       "      <td>2795</td>\n",
       "      <td>By signing this form, I am requesting and givi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95581557</td>\n",
       "      <td>../data/2020-01-21_Random_46-60_KATHLEEN.json</td>\n",
       "      <td>KATHLEEN</td>\n",
       "      <td>66236403</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>366</td>\n",
       "      <td>558</td>\n",
       "      <td>I understand that blood or blood products will...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>95581557</td>\n",
       "      <td>../data/2020-01-21_Random_46-60_KATHLEEN.json</td>\n",
       "      <td>KATHLEEN</td>\n",
       "      <td>66236403</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>366</td>\n",
       "      <td>558</td>\n",
       "      <td>My doctor will determine the amount of blood o...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69408590</td>\n",
       "      <td>../data/2020-01-21_Random_46-60_KATHLEEN.json</td>\n",
       "      <td>KATHLEEN</td>\n",
       "      <td>97685314</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>323</td>\n",
       "      <td>516</td>\n",
       "      <td>I authorize the release of any and all medical...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>69408590</td>\n",
       "      <td>../data/2020-01-21_Random_46-60_KATHLEEN.json</td>\n",
       "      <td>KATHLEEN</td>\n",
       "      <td>39472471</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "      <td>321</td>\n",
       "      <td>I voluntarily consent to medical care of a rou...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ICD_doc_id                                  json_filename annotator  \\\n",
       "0    95581557  ../data/2020-01-21_Random_46-60_KATHLEEN.json  KATHLEEN   \n",
       "1    95581557  ../data/2020-01-21_Random_46-60_KATHLEEN.json  KATHLEEN   \n",
       "2    95581557  ../data/2020-01-21_Random_46-60_KATHLEEN.json  KATHLEEN   \n",
       "3    69408590  ../data/2020-01-21_Random_46-60_KATHLEEN.json  KATHLEEN   \n",
       "4    69408590  ../data/2020-01-21_Random_46-60_KATHLEEN.json  KATHLEEN   \n",
       "\n",
       "   annotation_id  A  B  C  start_char  end_char  \\\n",
       "0       22668539  1  0  0        2613      2795   \n",
       "1       66236403  0  0  1         366       558   \n",
       "2       66236403  0  0  1         366       558   \n",
       "3       97685314  1  0  0         323       516   \n",
       "4       39472471  1  0  0         104       321   \n",
       "\n",
       "                                                text  sentence_count  \n",
       "0  By signing this form, I am requesting and givi...               1  \n",
       "1  I understand that blood or blood products will...               1  \n",
       "2  My doctor will determine the amount of blood o...               2  \n",
       "3  I authorize the release of any and all medical...               1  \n",
       "4  I voluntarily consent to medical care of a rou...               1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Load the preprocessed annotations\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_csv(\"processed_annotations/ANNOTATIONS_02-14-2020.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# Save all A or B annotations by annotator\n",
    "# \"\"\"\n",
    "\n",
    "# for annotator in set(df.annotator):\n",
    "#     annotator_df = df[(df.annotator == f\"{annotator}\") & ((df.A == 1) | (df.B == 1))]\n",
    "#     annotator_df.to_csv(f\"processed_annotations/{annotator}_AB_only.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE dropping duplicates 1782\n",
      "AFTER dropping duplicates 824\n"
     ]
    }
   ],
   "source": [
    "AB_only = df[((df.A == 1) | (df.B == 1))]\n",
    "\n",
    "AB_only = AB_only.drop(['json_filename', \n",
    "                        'annotator',\n",
    "                        'A',\n",
    "                        'B',\n",
    "                        'C', \n",
    "                        'start_char', \n",
    "                        'end_char',\n",
    "                        'sentence_count'], axis=1)\n",
    "\n",
    "print(f\"BEFORE dropping duplicates {len(AB_only)}\")\n",
    "AB_only = AB_only.drop_duplicates('text')\n",
    "print(f\"AFTER dropping duplicates {len(AB_only)}\")\n",
    "AB_only.head()\n",
    "\n",
    "\n",
    "AB_only.to_csv(\"processed_annotations/ALL_UNIQUE_ANNOTATIONS.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Align these puppies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ICD_doc_id     object\n",
       "sentece        object\n",
       "start_pos       int64\n",
       "num_words       int64\n",
       "num_chars       int64\n",
       "sentece_obj    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "random_doc = random.sample(d_map.keys(), 1)[0]\n",
    "    \n",
    "for idx, ref_row in ref[ref.ICD_doc_id == random_doc].iterrows():\n",
    "    \n",
    "    reference_sent = ref_row['sentece']     \n",
    "    inter_doc_annotations = df[df['ICD_doc_id'] == int(ref_row['ICD_doc_id'])]\n",
    "    \n",
    "    print(len(inter_doc_annotations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------\n",
      "score: 1.000\n",
      "REFERNCE: This consent is for attendance at a group medical appointment (group visit).\n",
      "ANNOTATION: This consent is for attendance at a group medical appointment (group visit).\n",
      "ANNOTATOR: `KATHLEEN` ----> LABELS: (A=0, B=0, C=1)\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------\n",
      "score: 1.000\n",
      "REFERNCE: A group visit is a medical appointment that involves more than one patient in the same room at a time.\n",
      "ANNOTATION: A group visit is a medical appointment that involves more than one patient in the same room at a time.\n",
      "ANNOTATOR: `KATHLEEN` ----> LABELS: (A=0, B=0, C=1)\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------\n",
      "score: 1.000\n",
      "REFERNCE: A group visit is a medical appointment that involves more than one patient in the same room at a time.\n",
      "ANNOTATION: A group visit is a medical appointment that involves more than one patient in the same room at a time.\n",
      "ANNOTATOR: `LIZ` ----> LABELS: (A=0, B=0, C=1)\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------\n",
      "score: 1.000\n",
      "REFERNCE: Group visits are generally started so that patients with similar conditions or symptoms can be seen more efficiently than when each patient is scheduled for an individual appointment.\n",
      "ANNOTATION: Group visits are generally started so that patients with similar conditions or symptoms can be seen more efficiently than when each patient is scheduled for an individual appointment.\n",
      "ANNOTATOR: `KATHLEEN` ----> LABELS: (A=0, B=0, C=1)\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------\n",
      "score: 1.000\n",
      "REFERNCE: I understand that I may have the option to be seen individually.\n",
      "ANNOTATION: I understand that I may have the option to be seen individually.\n",
      "ANNOTATOR: `KAYCEE` ----> LABELS: (A=0, B=0, C=1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n",
      "/opt/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n",
      "/opt/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n",
      "/opt/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n",
      "/opt/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n",
      "/opt/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n",
      "/opt/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n",
      "/opt/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n",
      "/opt/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n",
      "/opt/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n",
      "/opt/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n",
      "/opt/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n",
      "/opt/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n",
      "/opt/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n",
      "/opt/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n",
      "/opt/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n",
      "/opt/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n",
      "/opt/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n",
      "/opt/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n",
      "/opt/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n",
      "/opt/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.99\n",
    "new_rows = []\n",
    "\n",
    "def score_pair(reference__sentence, annotated_sentence):\n",
    "    \"\"\"A function to score a pair of sentences for similarity\n",
    "    \n",
    "    Args:\n",
    "        - reference__sentence (str): the reference sentence\n",
    "        - annotated_sentence (str): the canndidate sentence (annotation)\n",
    "        \n",
    "    Returns:\n",
    "        - score (float): a likelihood that the sentences are the same\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    ## TODO: need to handle empty vectors\n",
    "    sim = nlp(reference__sentence).similarity(nlp(annotated_sentence))\n",
    "    len_dff_sq = (len(reference__sentence) - len(annotated_sentence))**2\n",
    "    if len_dff_sq == 0:\n",
    "        len_dff_sq = 1\n",
    "    \n",
    "    len_weighted_sim = (1/len_dff_sq)*sim\n",
    "    \n",
    "    return len_weighted_sim\n",
    "    \n",
    "\n",
    "random_doc = random.sample(d_map.keys(), 1)[0]\n",
    "    \n",
    "for idx, ref_row in ref[ref.ICD_doc_id == random_doc].iterrows():\n",
    "    \n",
    "    reference_sent = ref_row['sentece']     \n",
    "    inter_doc_annotations = df[df['ICD_doc_id'] == int(ref_row['ICD_doc_id'])]\n",
    "    \n",
    "#     print(f\"Number of annotations: {len(inter_doc_annotations)}\")\n",
    "    \n",
    "    matches = 0\n",
    "    for aidx, annotation_row in inter_doc_annotations.iterrows():\n",
    "        annotated_text = annotation_row['text']\n",
    "        annotator = annotation_row['annotator']\n",
    "        A = annotation_row['A']\n",
    "        B = annotation_row['B']\n",
    "        C = annotation_row['C']\n",
    "        score = score_pair(reference_sent, annotated_text)\n",
    "        \n",
    "        if score > threshold:\n",
    "            matches += 1\n",
    "            print(\"---------------------------------------------------------------------------\")\n",
    "            print(\"---------------------------------------------------------------------------\")\n",
    "            print(\"---------------------------------------------------------------------------\")\n",
    "\n",
    "            print(f\"score: {score:.3f}\")\n",
    "            print(f\"REFERNCE: {reference_sent.strip()}\")\n",
    "            print(f\"ANNOTATION: {annotated_text.strip()}\")\n",
    "            print(f\"ANNOTATOR: `{annotator}` ----> LABELS: (A={A}, B={B}, C={C})\")\n",
    "            print()\n",
    "            \n",
    "#     print(f\"Number of Matches = {matches}\")\n",
    "    \n",
    "\n",
    "#         scores.append(score_pair(reference_sent, annotated_text))\n",
    "    \n",
    "#     print(f\"REFERENCE: {reference_sent.strip()}: MAX SCORE: {np.max(scores)}\")\n",
    "#     print(f\"MAX SCORE SENT: {str(inter_doc_annotations.iloc[[np.argmax(scores)]]['text'])}\")\n",
    "    \n",
    "#     print(\"---------------------------------------------------------------------------\")\n",
    "#     print(\"---------------------------------------------------------------------------\")\n",
    "#     print(\"---------------------------------------------------------------------------\")\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    if max score > THRESHOLD:\n",
    "        add annotation data and other data to new_rows\n",
    "    else:\n",
    "        move on\n",
    "    \"\"\"\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
